{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\Shaheer\\AppData\\Local\\Temp\\ipykernel_604\\176239620.py:35: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  A.ShiftScaleRotate(\n",
      "C:\\Users\\Shaheer\\AppData\\Local\\Temp\\ipykernel_604\\176239620.py:45: UserWarning: Argument(s) 'always_apply' are not valid for transform Resize\n",
      "  A.Resize(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "DIR_DATA = config['paths']['dir_data']\n",
    "PATH_DATA_CSV = config['paths']['path_data_csv']\n",
    "PATH_TRAIN_VAL_SPLIT = config['paths']['path_train_val_split']\n",
    "PATH_TEST_SPLIT = config['paths']['path_test_split']\n",
    "SAVE_PREPROCESSED_DIR = config['paths']['dir_preprocessed']\n",
    "\n",
    "SAVE_IMAGE_SIZE = 224\n",
    "N_AUGMENTATIONS = 5\n",
    "\n",
    "df_data = pd.read_csv(PATH_DATA_CSV, sep=';')\n",
    "\n",
    "with open(PATH_TRAIN_VAL_SPLIT, 'r') as file:\n",
    "    dict_list_pid = json.load(file)\n",
    "\n",
    "with open(PATH_TEST_SPLIT, 'r') as file:\n",
    "    list_test_pid = json.load(file)\n",
    "\n",
    "AUGMENTATION = A.Compose([\n",
    "    A.ColorJitter(0.2, 0.2, 0.2, 0.2, p=0.5),\n",
    "    A.CLAHE(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.2,\n",
    "        scale_limit=0.0,\n",
    "        rotate_limit=20,\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        border_mode=cv2.BORDER_CONSTANT, value=0, p=1.\n",
    "    ),\n",
    "])\n",
    "\n",
    "preprocessing = A.Compose([\n",
    "    A.Resize(\n",
    "        SAVE_IMAGE_SIZE, SAVE_IMAGE_SIZE, interpolation=cv2.INTER_CUBIC,\n",
    "        mask_interpolation=0, always_apply=True\n",
    "    ),\n",
    "])\n",
    "\n",
    "os.makedirs(os.path.join(SAVE_PREPROCESSED_DIR, 'train'))\n",
    "os.makedirs(os.path.join(SAVE_PREPROCESSED_DIR, 'val'))\n",
    "os.makedirs(os.path.join(SAVE_PREPROCESSED_DIR, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_square_with_zero_padding(image):\n",
    "    width, height = image.size\n",
    "\n",
    "    # Determine the size of the square\n",
    "    max_side = max(width, height)\n",
    "\n",
    "    # Create a new square image with black padding (0 for black in RGB or L modes)\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    if image.mode == \"RGB\":\n",
    "        padding_color = (0, 0, 0)  # Black for RGB images\n",
    "    elif image.mode == \"L\":\n",
    "        padding_color = 0  # Black for grayscale images\n",
    "\n",
    "    # Create a new square image\n",
    "    new_image = Image.new(image.mode, (max_side, max_side), padding_color)\n",
    "\n",
    "    # Calculate padding\n",
    "    padding_left = (max_side - width) // 2\n",
    "    padding_top = (max_side - height) // 2\n",
    "\n",
    "    # Paste the original image in the center of the new square image\n",
    "    new_image.paste(image, (padding_left, padding_top))\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 896)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pid_train = []\n",
    "list_pid_val = []\n",
    "for _, v in dict_list_pid.items():\n",
    "    list_pid_train.extend(v[0])\n",
    "    list_pid_val.extend(v[1])\n",
    "list_pid_train = list(set(list_pid_train))\n",
    "list_pid_val   = list(set(list_pid_val))\n",
    "\n",
    "len(list_pid_train), len(list_pid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7164it [06:59, 17.07it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m img \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m AUGMENTATION:\n\u001b[1;32m---> 19\u001b[0m     augmented \u001b[38;5;241m=\u001b[39m \u001b[43mAUGMENTATION\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     img \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m img_ann \u001b[38;5;241m=\u001b[39m preprocessing(image\u001b[38;5;241m=\u001b[39mimg)\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\core\\composition.py:610\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m--> 610\u001b[0m     data \u001b[38;5;241m=\u001b[39m t(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_transform_params(t, data)\n\u001b[0;32m    612\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_data_post_transform(data)\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\core\\transforms_interface.py:273\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[1;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic:\n\u001b[0;32m    272\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_with_params(params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\core\\transforms_interface.py:310\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key2func[key]\n\u001b[0;32m    309\u001b[0m         res[key] \u001b[38;5;241m=\u001b[39m ensure_contiguous_output(\n\u001b[1;32m--> 310\u001b[0m             target_function(ensure_contiguous_output(arg), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams),\n\u001b[0;32m    311\u001b[0m         )\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m arg\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\augmentations\\geometric\\transforms.py:800\u001b[0m, in \u001b[0;36mAffine.apply\u001b[1;34m(self, img, matrix, output_shape, **params)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    783\u001b[0m     img: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any,\n\u001b[0;32m    787\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the affine transform to an image.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    798\u001b[0m \n\u001b[0;32m    799\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfgeometric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarp_affine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mborder_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mborder_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albucore\\decorators.py:42\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[1;34m(img, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_function\u001b[39m(img: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     41\u001b[0m     shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 42\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(img, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m NUM_MULTI_CHANNEL_DIMENSIONS \u001b[38;5;129;01mand\u001b[39;00m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m MONO_CHANNEL_DIMENSIONS:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexpand_dims(result, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py:634\u001b[0m, in \u001b[0;36mwarp_affine\u001b[1;34m(image, matrix, interpolation, fill, border_mode, output_shape)\u001b[0m\n\u001b[0;32m    624\u001b[0m cv2_matrix \u001b[38;5;241m=\u001b[39m matrix[:\u001b[38;5;241m2\u001b[39m, :]\n\u001b[0;32m    626\u001b[0m warp_fn \u001b[38;5;241m=\u001b[39m maybe_process_in_chunks(\n\u001b[0;32m    627\u001b[0m     warp_affine_with_value_extension,\n\u001b[0;32m    628\u001b[0m     matrix\u001b[38;5;241m=\u001b[39mcv2_matrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m     border_value\u001b[38;5;241m=\u001b[39mfill,\n\u001b[0;32m    633\u001b[0m )\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwarp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albucore\\utils.py:99\u001b[0m, in \u001b[0;36mmaybe_process_in_chunks.<locals>.__process_fn\u001b[1;34m(img, *process_args, **process_kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m             chunks\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdstack(chunks)\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m process_fn(img, \u001b[38;5;241m*\u001b[39mall_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shaheer\\micromamba\\envs\\fetalclip\\lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py:582\u001b[0m, in \u001b[0;36mwarp_affine_with_value_extension\u001b[1;34m(image, matrix, dsize, flags, border_mode, border_value)\u001b[0m\n\u001b[0;32m    579\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m get_num_channels(image)\n\u001b[0;32m    580\u001b[0m extended_value \u001b[38;5;241m=\u001b[39m extend_value(border_value, num_channels)\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarpAffine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mborderMode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mborder_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mborderValue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df_data.iterrows()):\n",
    "    pid = row['Image_name'].split('_')[0]\n",
    "    \n",
    "    if pid not in list_pid_train:\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(os.path.join(DIR_DATA, f\"{row['Image_name']}.png\"))\n",
    "    \n",
    "    img = make_image_square_with_zero_padding(img)\n",
    "\n",
    "    img = np.array(img)\n",
    "\n",
    "    data = {'img': img.copy()}\n",
    "    \n",
    "    for i in range(N_AUGMENTATIONS):\n",
    "        img = data['img'].copy()\n",
    "\n",
    "        if AUGMENTATION:\n",
    "            augmented = AUGMENTATION(image=img)\n",
    "            img = augmented['image']\n",
    "        \n",
    "        img_ann = preprocessing(image=img)\n",
    "        img = img_ann['image']\n",
    "        \n",
    "        np.savez(\n",
    "            os.path.join(SAVE_PREPROCESSED_DIR, \"train\", f\"{row['Image_name']}_{i}.npz\"),\n",
    "            img=img, label=row['Plane'],\n",
    "        )\n",
    "\n",
    "        img = Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12400it [01:21, 151.59it/s] \n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df_data.iterrows()):\n",
    "    pid = row['Image_name'].split('_')[0]\n",
    "    \n",
    "    if pid not in list_pid_val:\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(os.path.join(DIR_DATA, f\"{row['Image_name']}.png\"))\n",
    "    \n",
    "    img = make_image_square_with_zero_padding(img)\n",
    "\n",
    "    img = np.array(img)\n",
    "\n",
    "    data = {'img': img.copy()}\n",
    "    \n",
    "    img = data['img'].copy()\n",
    "    \n",
    "    img_ann = preprocessing(image=img)\n",
    "    img = img_ann['image']\n",
    "    \n",
    "    np.savez(\n",
    "        os.path.join(SAVE_PREPROCESSED_DIR, \"val\", f\"{row['Image_name']}.npz\"),\n",
    "        img=img, label=row['Plane'],\n",
    "    )\n",
    "\n",
    "    img = Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12400it [01:09, 179.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df_data.iterrows()):\n",
    "    pid = row['Image_name'].split('_')[0]\n",
    "    \n",
    "    if pid not in list_test_pid:\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(os.path.join(DIR_DATA, f\"{row['Image_name']}.png\"))\n",
    "    \n",
    "    img = make_image_square_with_zero_padding(img)\n",
    "\n",
    "    img = np.array(img)\n",
    "\n",
    "    data = {'img': img.copy()}\n",
    "    \n",
    "    img = data['img'].copy()\n",
    "    \n",
    "    img_ann = preprocessing(image=img)\n",
    "    img = img_ann['image']\n",
    "    \n",
    "    np.savez(\n",
    "        os.path.join(SAVE_PREPROCESSED_DIR, \"test\", f\"{row['Image_name']}.npz\"),\n",
    "        img=img, label=row['Plane'],\n",
    "    )\n",
    "\n",
    "    img = Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'preprocessed_data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed_data/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_data/val\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_data/test\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'preprocessed_data/train'"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('preprocessed_data/train')))\n",
    "print(len(os.listdir('preprocessed_data/val')))\n",
    "print(len(os.listdir('preprocessed_data/test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fetalclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
